This course was a comprehensive guide to the core mechanism of the diffusion model, i.e., diffusing information in multiple steps. Each step goes through several transformations to gradually refine the predicted distribution of the next token. In this course, we aimed to get more sprites from the set we already had, and we used a neural network to do so, followed by conditioning based on the observed token and applying a set of transformation functions. The neural network used here was UNet. The transformation function acts like a diffusion operator and updates the distribution. We obtain control using embeddings and adding context. Finally, we learned how to speed up the process, using DDIM instead of DDPM as it is deterministic, where the latter is probabilistic, and DDIM can skip timesteps. Hence it is faster.